{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de aprendizado de máquina para reconhecimento de imagens de frutas ou verduras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomRotation\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomZoom\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficiente de aleatoriedade\n",
    "tf.random.set_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para dados de treino\n",
    "caminho_dados_treino = Path('fruits-360/Training')\n",
    "# Caminho para dados de teste\n",
    "caminho_dados_teste = Path('fruits-360/Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listagem do conteúdo da pasta\n",
    "imagens_treino = list(caminho_dados_treino.glob('*/*'))\n",
    "# Extração de apenas o valor com o caminho de cada imagem (removendo PosixPath)\n",
    "imagens_treino = list(map(lambda x: str(x), imagens_treino))\n",
    "imagens_treino = list(map(lambda x: str(x).replace('\\\\', '/'), imagens_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruits-360/Training/Apple Crimson Snow/r_90_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_91_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_92_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_93_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_94_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_95_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_96_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_97_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_98_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_99_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_9_100.jpg']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagens_treino[925:936]\n",
    "# O nome dos arquivos prejudica a compreensão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pré-processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenção do label de cada imagem\n",
    "def extrai_label(caminho_imagem):\n",
    "    return caminho_imagem.split(\"/\")[-2]\n",
    "\n",
    "imagens_treino_labels = list(map(lambda x: extrai_label(x), imagens_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple Crimson Snow',\n",
       " 'Apple Crimson Snow',\n",
       " 'Apple Crimson Snow',\n",
       " 'Apple Crimson Snow']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagens_treino_labels[840:844]\n",
    "# O sistema não reconhece strings, para isso, é necessário converte-la em números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do objeto\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "imagens_treino_labels = encoder.fit_transform(imagens_treino_labels)\n",
    "\n",
    "# Aplicação do one-hot-encoding nos labels\n",
    "imagens_treino_labels = tf.keras.utils.to_categorical(imagens_treino_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados de treino e de validação\n",
    "x_treino, x_valid, y_treino, y_valid = train_test_split(imagens_treino, imagens_treino_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Augmentation\n",
    "\n",
    "Consiste em modificar as imagens para que o modelo fique mais preciso em identificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionamento das imagens\n",
    "img_size = 224\n",
    "resize = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.Resizing(img_size, img_size)])\n",
    "\n",
    "# Criação do objeto do Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([RandomFlip(\"horizontal\"),\n",
    "                                         RandomRotation(0.2),\n",
    "                                         RandomZoom(height_factor = (-0.3,-0.2)) ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparo dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametros\n",
    "batch_size = 32\n",
    "autotune = tf.data.experimental.AUTOTUNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento e transformação de imagens\n",
    "def carrega_transforma(image, label):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels = 3)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados no formato do TensorFlow\n",
    "# Dataset augmentation é usado apenas em treino\n",
    "def prepara_dataset(path, labels, train = True):\n",
    "    image_paths = tf.convert_to_tensor(path)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "    dataset = dataset.map(lambda image, label: carrega_transforma(image, label)) \n",
    "    dataset = dataset.map(lambda image, label: (resize(image), label), num_parallel_calls = autotune)\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Se train = True aplica dataset augmentation\n",
    "    if train:\n",
    "        dataset = dataset.map(lambda image, label: (data_augmentation(image), label), num_parallel_calls = autotune)\n",
    "  \n",
    "    # Se train = False repete sobre o dataset e retorna\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# Criação do dataset de treino\n",
    "dataset_treino = prepara_dataset(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "imagem, label = next(iter(dataset_treino))\n",
    "print(imagem.shape) # \"Lotes\" de 32 imagens 224 x 244 de tamanho e 3 canais de cores (RGB)\n",
    "print(label.shape) # 32 labels e um vetor de 131 itens na pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do dataset de validação\n",
    "dataset_valid = prepara_dataset(X_valid, y_valid, train = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento de um modelo pre-treinado\n",
    "modelo_pre = EfficientNetB3(input_shape = (224, 224, 3), include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adição das camadas ao modelo_pre\n",
    "modelo = tf.keras.Sequential([modelo_pre,\n",
    "                            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                            tf.keras.layers.Dense(131, activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb3 (Functional)  (None, 7, 7, 1536)       10783535  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1536)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 131)               201347    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,984,882\n",
      "Trainable params: 10,897,579\n",
      "Non-trainable params: 87,303\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sumario do modelo\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros\n",
    "lr = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "ep = 1e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "modelo.compile(optimizer = Adam(learning_rate = lr, \n",
    "                                beta_1 = beta1, \n",
    "                                beta_2 = beta2, \n",
    "                                epsilon = ep),\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy', Precision(name = 'precision'), Recall(name = 'recall')])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0dd756d58e667554e208f97cb76f791692cf26662bafeb14c0abad0e4482b56b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
