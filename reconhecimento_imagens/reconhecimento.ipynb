{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de aprendizado de máquina para reconhecimento de imagens de frutas ou verduras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomRotation\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomZoom\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficiente de aleatoriedade\n",
    "tf.random.set_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para dados de treino\n",
    "caminho_dados_treino = Path('fruits-360/Training')\n",
    "# Caminho para dados de teste\n",
    "caminho_dados_teste = Path('fruits-360/Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listagem do conteúdo da pasta\n",
    "imagens_treino = list(caminho_dados_treino.glob('*/*'))\n",
    "# Extração de apenas o valor com o caminho de cada imagem (removendo PosixPath)\n",
    "imagens_treino = list(map(lambda x: str(x), imagens_treino))\n",
    "imagens_treino = list(map(lambda x: str(x).replace('\\\\', '/'), imagens_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruits-360/Training/Apple Crimson Snow/r_90_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_91_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_92_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_93_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_94_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_95_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_96_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_97_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_98_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_99_100.jpg',\n",
       " 'fruits-360/Training/Apple Crimson Snow/r_9_100.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagens_treino[925:936]\n",
    "# O nome dos arquivos prejudica a compreensão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pré-processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenção do label de cada imagem\n",
    "def extrai_label(caminho_imagem):\n",
    "    return caminho_imagem.split(\"/\")[-2]\n",
    "\n",
    "imagens_treino_labels = list(map(lambda x: extrai_label(x), imagens_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple Crimson Snow',\n",
       " 'Apple Crimson Snow',\n",
       " 'Apple Crimson Snow',\n",
       " 'Apple Crimson Snow']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagens_treino_labels[840:844]\n",
    "# O sistema não reconhece strings, para isso, é necessário converte-la em números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do objeto\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "imagens_treino_labels = encoder.fit_transform(imagens_treino_labels)\n",
    "\n",
    "# Aplicação do one-hot-encoding nos labels\n",
    "imagens_treino_labels = tf.keras.utils.to_categorical(imagens_treino_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados de treino e de validação\n",
    "x_treino, x_valid, y_treino, y_valid = train_test_split(imagens_treino, imagens_treino_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Augmentation\n",
    "\n",
    "Consiste em modificar as imagens para que o modelo fique mais preciso em identificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionamento das imagens\n",
    "img_size = 224\n",
    "resize = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.Resizing(img_size, img_size)])\n",
    "\n",
    "# Criação do objeto do Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([RandomFlip(\"horizontal\"),\n",
    "                                         RandomRotation(0.2),\n",
    "                                         RandomZoom(height_factor = (-0.3,-0.2)) ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparo dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametros\n",
    "batch_size = 32\n",
    "autotune = tf.data.experimental.AUTOTUNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento e transformação de imagens\n",
    "def carrega_transforma(image, label):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels = 3)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados no formato do TensorFlow\n",
    "# Dataset augmentation é usado apenas em treino\n",
    "def prepara_dataset(path, labels, train = True):\n",
    "    image_paths = tf.convert_to_tensor(path)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "    dataset = dataset.map(lambda image, label: carrega_transforma(image, label)) \n",
    "    dataset = dataset.map(lambda image, label: (resize(image), label), num_parallel_calls = autotune)\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Se train = True aplica dataset augmentation\n",
    "    if train:\n",
    "        dataset = dataset.map(lambda image, label: (data_augmentation(image), label), num_parallel_calls = autotune)\n",
    "  \n",
    "    # Se train = False repete sobre o dataset e retorna\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# Criação do dataset de treino\n",
    "dataset_treino = prepara_dataset(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "(32, 131)\n"
     ]
    }
   ],
   "source": [
    "# Shape\n",
    "imagem, label = next(iter(dataset_treino))\n",
    "print(imagem.shape) # \"Lotes\" de 32 imagens 224 x 244 de tamanho e 3 canais de cores (RGB)\n",
    "print(label.shape) # 32 labels e um vetor de 131 itens na pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do dataset de validação\n",
    "dataset_valid = prepara_dataset(x_valid, y_valid, train = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento de um modelo pre-treinado\n",
    "modelo_pre = EfficientNetB3(input_shape = (224, 224, 3), include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adição das camadas ao modelo_pre\n",
    "modelo = tf.keras.Sequential([modelo_pre,\n",
    "                            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                            tf.keras.layers.Dense(131, activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb3 (Functional)  (None, 7, 7, 1536)       10783535  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1536)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 131)               201347    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,984,882\n",
      "Trainable params: 10,897,579\n",
      "Non-trainable params: 87,303\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sumario do modelo\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros\n",
    "lr = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "ep = 1e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "modelo.compile(optimizer = Adam(learning_rate = lr, \n",
    "                                beta_1 = beta1, \n",
    "                                beta_2 = beta2, \n",
    "                                epsilon = ep),\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy', Precision(name = 'precision'), Recall(name = 'recall')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3/1586 [..............................] - ETA: 85:05:03 - loss: 4.8930 - accuracy: 0.0208 - precision: 0.0000e+00 - recall: 0.0000e+00   "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Treino do modelo\n",
    "history = modelo.fit(dataset_treino,\n",
    "                    steps_per_epoch = len(x_treino)//batch_size,\n",
    "                    epochs = 1,\n",
    "                    validation_data = dataset_valid,\n",
    "                    validation_steps = len(y_treino)//batch_size)\n",
    "# Leva horas para treinar, atenção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarte\n",
    "modelo.layers[0].trainable = False\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"modelo/modelo_frutas.h5\", \n",
    "                                                verbose = 1, \n",
    "                                                save_best = True, \n",
    "                                                save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stop\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience = 4) \n",
    "\n",
    "# Sumário\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Treino aperfeiçoado com as novas adições\n",
    "history = modelo.fit(dataset_treino,\n",
    "                     steps_per_epoch = len(X_treino)//batch_size,\n",
    "                     epochs = 6,\n",
    "                     validation_data = dataset_valid,\n",
    "                     validation_steps = len(y_treino)//batch_size,\n",
    "                     callbacks = [checkpoint, early_stop])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para carregar os pesos, precisamos descongelar as camadas\n",
    "modelo.layers[0].trainable = True   \n",
    "\n",
    "# Carregamento dos pesos do ponto de verificação e reavaliação\n",
    "modelo.load_weights(\"modelo/modelo_frutas.h5\")     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando e preparando os dados de teste\n",
    "camninho_imagens_teste = list(caminho_dados_teste.glob(\"*/*\"))\n",
    "imagens_teste = list(map(lambda x: str(x), camninho_imagens_teste))\n",
    "imagens_teste_labels = list(map(lambda x: extrai_label(x), imagens_teste))\n",
    "imagens_teste_labels = encoder.fit_transform(imagens_teste_labels)\n",
    "imagens_teste_labels = tf.keras.utils.to_categorical(imagens_teste_labels)\n",
    "test_image_paths = tf.convert_to_tensor(imagens_teste)\n",
    "test_image_labels = tf.convert_to_tensor(imagens_teste_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para decode das imagens\n",
    "def decode_imagens(image, label):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels = 3)\n",
    "    image = tf.image.resize(image, [224,224], method = \"bilinear\")\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do dataset de teste\n",
    "dataset_teste = (tf.data.Dataset\n",
    "                 .from_tensor_slices((imagens_teste, imagens_teste_labels))\n",
    "                 .map(decode_imagens)\n",
    "                 .batch(batch_size))\n",
    "\n",
    "# Shape\n",
    "imagem, label = next(iter(dataset_teste))\n",
    "print(imagem.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização uma imagem de teste\n",
    "print(encoder.inverse_transform(np.argmax(label, axis = 1))[0])\n",
    "plt.imshow((imagem[0].numpy()/255).reshape(224,224,3))\n",
    "\n",
    "# Avaliação do modelo\n",
    "loss, acc, prec, rec = modelo.evaluate(dataset_teste)\n",
    "\n",
    "print(\"Acurácia: \", acc)\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", rec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Previsão com o novo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar uma nova imagem\n",
    "def carregamento_imagem(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_jpeg(image, channels = 3)\n",
    "    image = tf.image.resize(image, [224,224], method = \"bilinear\")\n",
    "    plt.imshow(image.numpy()/255)\n",
    "    image = tf.expand_dims(image, 0) \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para fazer previsões\n",
    "def previsao(image_path, model, enc):\n",
    "    image = carregamento_imagem(image_path)\n",
    "    prediction = model.predict(image)\n",
    "    pred = np.argmax(prediction, axis = 1) \n",
    "    return enc.inverse_transform(pred)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão\n",
    "previsao(\"imagens/imagem1.jpg\", modelo, encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0dd756d58e667554e208f97cb76f791692cf26662bafeb14c0abad0e4482b56b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
